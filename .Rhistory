map <- get_map(location = 'Europe', zoom = 4)
library(ggmap)
map <- get_map(location = 'Europe', zoom = 4)
mapPoints <- ggmap(map) + geom_point(aes(x = longitude, y = latitude),data = negatives, alpha = .5, color = "red")
mapPoints
mapPoints <- ggmap(map) + geom_point(aes(x = longitude, y = latitude),data = negatives, alpha = .5, color = "red")
data_gelocated<-read.csv(file ="../Data/data_geolocated_with_class.csv")
setwd("~/Documents/HU_Berlin/WI_1516/refugeestest/IS refugees")
data_gelocated<-read.csv(file ="../Data/data_geolocated_with_class.csv")
positives<-data_gelocated[data_gelocated$class=="pos",]
negatives<-data_gelocated[data_gelocated$class=="neg",]
mapPoints <- ggmap(map) + geom_point(aes(x = longitude, y = latitude),data = negatives, alpha = .5, color = "red")
mapPoints
length(negatives)
length(negatives[,1])
length(data_gelocated[,1])
5945-2811
map <- get_map(location = 'Europe', zoom = 3)
mapPoints <- ggmap(map) + geom_point(aes(x = longitude, y = latitude),data = negatives, alpha = .5, color = "red")
mapPoints
5945-2238
map <- get_map(location = 'America', zoom = 3)
mapPoints <- ggmap(map) + geom_point(aes(x = longitude, y = latitude),data = negatives, alpha = .5, color = "red")
mapPoints
5945-4461
control<-trainControl(method="cv", number = 5, repeats=5)
require(caret)
require("caret")
control<-trainControl(method="cv", number = 5, repeats=5)
ctrl <- trainControl(method="cv",number=5)
library(caret)
library(caret)
library(nnet)
library(randomForest)
library(e1071)
setwd("~/Documents/HU Berlin/WI 1516/BADS/Aufgabe/BADS")
dir<-getwd()
### Not on windows #######
#library(doMC)           #
#registerDoMC(cores = 4) #
##########################
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
setwd("~/Documents/HU_Berlin/WI 1516/BADS/Aufgabe/BADS")
dir<-getwd()
### Not on windows #######
#library(doMC)           #
#registerDoMC(cores = 4) #
##########################
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
setwd("~/Documents/HU_Berlin/WI_1516/BADS/Aufgabe/BADS")
dir<-getwd()
### Not on windows #######
#library(doMC)           #
#registerDoMC(cores = 4) #
##########################
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
head(negative_set)
setwd("~/Documents/HU_Berlin/WI_1516/refugeestest/IS refugees")
data.refugees<-read.csv(file ="../Data/Data_refugees_nachgeladen040116.csv")
refs_tag_pro_line<-read.csv(file ="../Data/Data_refugees_tag_pro_line.csv")
dat<-refs_tag_pro_line
negative_ids<-dat[which(dat$tagss=="refugeesnotwelcome"|dat$tagss=="nomorerefugees"|dat$tagss=="fuckrefugees"),]
negative_ids_cleanet<-negative_ids[!duplicated(negative_ids[,2]),]
positive_ids<-dat[which(dat$tagss=="refugeeswelcome"),]
positive_id_cleaned<-positive_ids[!duplicated(positive_ids[,2]),]
seeker_ids<-dat[which(dat$tagss=="amazing"|dat$tagss=="follow4follow"|dat$tagss=="like4like"
|dat$tagss=="look"|
dat$tagss=="instalike"|
dat$tagss=="swag"|
dat$tagss=="instafollow"|
dat$tagss=="art"
),]
seeker_ids_cleaned<-seeker_ids[!duplicated(seeker_ids[,2]),]
negative_ids_cleanet_ids<-negative_ids_cleanet[,2]
positive_id_cleaned_id<-positive_id_cleaned[,2]
seeker_ids_cleaned_id<-seeker_ids_cleaned[,2]
negative_ids_cleanet_ids_cleaned<-negative_ids_cleanet_ids[!(negative_ids_cleanet_ids %in% positive_id_cleaned_id)]
positive_id_cleaned_id_cleaned<-positive_id_cleaned_id[!(positive_id_cleaned_id %in% negative_ids_cleanet_ids)]
positive_id_cleaned_id_cleaned<-positive_id_cleaned_id[!(positive_id_cleaned_id_cleaned %in% seeker_ids_cleaned_id)]
negative_set<-data.refugees[data.refugees$id %in% negative_ids_cleanet_ids_cleaned,]
positive_set<-data.refugees[data.refugees$id %in% positive_id_cleaned_id_cleaned,]
colnames(negative_set)
positive_subset<-positive_set[sample(nrow(positive_set), length(negative_set[,1])), ]
sapply(1:length(negative_set[,1]), function(x) write( gsub("[[:punct:]]"," ",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write( gsub("[[:punct:]]"," ",paste0(positive_subset[x,13])), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write(paste0(negative_set[x,13]), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write(paste0(positive_subset[x,13]), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
colnames(negative_set)
sapply(1:length(negative_set[,1]), function(x) write(negative_set$caption, file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write(positive_subset$caption, file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write(negative_set$caption[x], file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
colnames(negative_set)
sapply(1:length(negative_set[,1]), function(x) write( gsub("#[^ ]+ "," ",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#?://.*?\\s "," ",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("^R\\w+"," ",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub(" # [0-9A-Fa-f] ","",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#[0-9A-Fa-f] ","",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#* ","",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("[:space:]#*[:space:]","",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome|#" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome|#" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome|#nomorerefugees|#fuckrefugees" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome|#nomorerefugees|#fuckrefugees|#" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write( gsub("#refugeeswelcome|[[:punct:]]","",paste0(positive_subset[x,13])), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome|#nomorerefugees|#fuckrefugees|refugeeswelcome|#" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeeswelcome|#nomorerefugees|#fuckrefugees|refugeeswelcome|#" ,"",paste0(negative_set[x,13])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write( gsub("#refugeeswelcome|[[:punct:]]","",paste0(positive_subset[x,13])), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
length(negative_set[,1])
colnames(negative_set)
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeesnotwelcome|#nomorerefugees|#fuckrefugees|refugeesnotwelcome|nomorerefugees|fuckrefugees|#" ,"",paste0(negative_set[x,13],negative_set[x,14])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write( gsub("#refugeeswelcome|refugeeswelcome|[[:punct:]]","",paste0(positive_subset[x,13],positive_subset[x,14])), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeesnotwelcome|#nomorerefugees|#fuckrefugees|refugeesnotwelcome|nomorerefugees|fuckrefugees|#" ,"",paste0(negative_set[x,13]," ",negative_set[x,14])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write( gsub("#refugeeswelcome|refugeeswelcome|[[:punct:]]","",paste0(positive_subset[x,13]," ",positive_subset[x,14])), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
sapply(1:length(negative_set[,1]), function(x) write( gsub("#refugeesnotwelcome|#nomorerefugees|#fuckrefugees|refugeesnotwelcome|nomorerefugees|fuckrefugees|#" ," ",paste0(negative_set[x,13]," ",negative_set[x,14])), file=paste0("../Data/weka_analysis_onlycomment/neg/",as.character(negative_set$id[x]),".txt")))
sapply(1:length(positive_subset[,1]), function(x) write( gsub("#refugeeswelcome|refugeeswelcome|[[:punct:]]"," ",paste0(positive_subset[x,13]," ",positive_subset[x,14])), file=paste0("../Data/weka_analysis_onlycomment/pos/",as.character(positive_subset$id[x]),".txt")))
length(data_gelocated[,1])
length(data.refugees[,1])
setwd("~/Documents/HU Berlin/WI 1516/BADS/Aufgabe/BADS")
setwd("~/Documents/HU_Berlin/WI_1516/BADS/Aufgabe/BADS")
setwd("~/Documents/HU_Berlin/WI_1516/BADS/Aufgabe/BADS")
dir<-getwd()
dir<-getwd()
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
source(paste0(dir, "/Code/Init.R"))
source(paste0(dir, "/Code/DataLoader.R"))
test_set = getTestset(dir)
numericVariables = getNumericVariables(test_set)
categoricVariables <- test_set[setdiff(colnames(test_set), colnames(numericVariables))]
continousVariablesname <- getContinousset(dir)
print("Loaded Dataset")
source(paste0(dir,"/Code/missingValueHandler.R"))
test_set <- loadImputedTestSet(paste0(dir, "/Data/ImputedData_testSet.csv"))
source(paste0(dir, "/Code/Outliers.R"))
#z-score one-dimentional outlier handling
test_set_withoutOutlier<- handle.Outliers.for.Matrix(test_set)
print("Finished Outlier Handling")
#Data scaling with z-score
source(paste0(dir, "/Code/scaling.R"))
test_set <- z.scale.data(m=test_set,continous.var=continousVariablesname)
test_set_withoutOutlier<- z.scale.data(m=test_set_withoutOutlier,continous.var=continousVariablesname)
print("Finished Scaling")
source(paste0(dir, "/Code/ModelTrainer.R"))
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]), "churn")
test_set <- test_set[,selectedFeatures]
selectedFeatures
colnames(test_set)
selectedFeatures <- getSelectedFeatureSet(dir)
test_set <- test_set[,selectedFeatures]
selectedFeatures <- c(as.vector(selectedFeatures[,1]))
test_set <- test_set[,selectedFeatures]
source(paste0(dir, "/Code/PCA.R"))
test_set<-rebuild_components_for_test_set(test_set)
print("Data is ready")
test_set<-rebuild_components_for_test_set(test_set)
source(paste0(dir, "/Code/PCA.R"))
test_set<-rebuild_components_for_test_set(test_set)
head(test_set)
setwd("~/Documents/HU_Berlin/WI_1516/BADS/Aufgabe/BADS")
dir<-getwd()
### Not on windows #######
#library(doMC)           #
#registerDoMC(cores = 4) #
##########################
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
cl <- makeCluster((detectCores()))
registerDoParallel(cl)
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
trainingset = getTrainigset(dir)
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
continousVariablesname <- getContinousset(dir)
#Exploratory Data Analysis
source(paste0(dir, "/Code/ExploratoryDataAnalysis.R"))
#createUsefulPlots(trainingset, numericVariables, categoricVariables)
print("Loaded Dataset")
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
#trainingset <- getImputedData(trainingset)
#numericVariables = getNumericVariables(trainingset)
#categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(trainingset))]
#write.csv(trainingset, paste0(dir, "/Data/ImputedData.csv"), sep = ",")
trainingset <- loadImputedTrainingset(paste0(dir, "/Data/ImputedData.csv"))
numericVariables = getNumericVariables(trainingset)
categoricVariables <- trainingset[setdiff(colnames(trainingset), colnames(numericVariables))]
print("Finished Missing Value Handling")
#trainingset <- trainingset[sample(1:50000,20000, replace = FALSE),]
#Outlier Handling
source(paste0(dir, "/Code/Outliers.R"))
#z-score one-dimentional outlier handling
trainingset_withoutOutlier<- handle.Outliers.for.Matrix(trainingset)
print("Finished Outlier Handling")
source(paste0(dir, "/Code/scaling.R"))
#traingsset
trainingset <- z.scale.data(m=trainingset,continous.var=continousVariablesname)
#traingsset_withoutOutlier
trainingset_withoutOutlier<- z.scale.data(m=trainingset_withoutOutlier,continous.var=continousVariablesname)
print("Finished Scaling")
#Corelation
#identify highly corelated coplete veriables
#source(paste0(dir, "/Code/Correlation.R"))
#data<-trainingset_withoutOutlier
#trainingset_withoutCorrelated<-handle.highly.correlated.for.Matrix(data, .75,
#        which(colnames(data)=="Customer_ID"|colnames(data)=="churn"))
#####when skeaping the correlation
#trainingset_withoutCorrelated<-trainingset_withoutOutlier
#identify highly corelated coplete veriables (only numeric)
#correlationMatrix <- cor(trainingset)
#correlationMatrix2 <- cor(trainingset_withoutOutlier)
##summary(correlationMatrix[upper.tri(correlationMatrix)])
# find attributes that are highly corrected (ideally >0.75)
#highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.90, verbose = FALSE)
#highlyCorrelated2 <- findCorrelation(correlationMatrix2, cutoff=0.90, verbose = FALSE)
#delete highly corelated columns
#trainingset<-trainingset[,-highlyCorrelated]
#trainingset_withoutOutlier<-trainingset_withoutOutlier[,-highlyCorrelated2]
#Feature selection
# source(paste0(dir, "/Code/FeatureSelection.R"))
# new dataset only containing selected features
#selectedFeatures <- getSelectedFeatureSet(dir)
#selectedFeatures <- c(as.vector(selectedFeatures[,1]), "churn")
source(paste0(dir, "/Code/ModelTrainer.R"))
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]), "churn")
trainingset <- trainingset[,selectedFeatures]
trainingset_withoutOutlier <- trainingset_withoutOutlier[,selectedFeatures]
featureSelection <- function(){
rf <- trainRandomForest(trainingset)
importance <- varImp(rf, type= 1, scale=FALSE)
importance_ranking <- importance$importance
importance_ranking <- as.vector(importance_ranking)
print("Importance:")
print(importance)
print("############################################")
print("Importance Ranking:")
print(importance_ranking)
}
source(paste0(dir, "/Code/PCA.R"))
trainingset<-executePCA(trainingset)
colnames(trainingset)
data<-trainingset
data_numeric<-getNumericVariables(data)
data_numeric<-data_numeric[,-which(colnames(data_numeric)=="Customer_ID")]
new_data_numeric<-pca(data_numeric)
colnames(data_numeric)
trainingset_st_numeric<-data_numeric
original_dimNumber<-length(trainingset_st_numeric)
pca<-princomp(x=trainingset_st_numeric, scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[1:1000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[1:10000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[1:100000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[1:10000,], scores=TRUE, cor = TRUE)
length(trainingset_st_numeric[,2])
pca<-princomp(x=trainingset_st_numeric[1:40000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[1:30000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:30000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[25000:30000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:25000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[24000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[23000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[22000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[21000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:25000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[1:25000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:25000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[25000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[24000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[23000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[22000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[21000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[21000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[24000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:26000,], scores=TRUE, cor = TRUE)
pca<-princomp(x=trainingset_st_numeric[20000:26000,], scores=TRUE)
pca<-princomp(x=trainingset_st_numeric, scores=TRUE)
pca<-princomp(x=trainingset_st_numeric, scores=TRUE)
trainingset<-executePCA(trainingset)
source(paste0(dir, "/Code/PCA.R"))
trainingset<-executePCA(trainingset)
source(paste0(dir, "/Code/PCA.R"))
source(paste0(dir, "/Code/PCA.R"))
trainingset<-executePCA(trainingset)
trainingset_withoutOutlier<-executePCA(trainingset_withoutOutlier)
source(paste0(dir, "/Code/PCA.R"))
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]), "churn")
test_set <- test_set[,selectedFeatures]
test_set <- test_set[,selectedFeatures]
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]))
test_set <- test_set[,selectedFeatures]
source(paste0(dir, "/Code/ModelTrainer.R"))
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]))
test_set <- test_set[,selectedFeatures]
colnames(test_set)
setwd("~/Documents/HU_Berlin/WI_1516/BADS/Aufgabe/BADS")
dir<-getwd()
source(paste0(dir, "/Code/Utils.R"))
source(paste0(dir, "/Code/PlotHelper.R"))
#Script to install and load needed packages
source(paste0(dir, "/Code/Init.R"))
#Load Data
source(paste0(dir, "/Code/DataLoader.R"))
test_set = getTestset(dir)
numericVariables = getNumericVariables(test_set)
categoricVariables <- test_set[setdiff(colnames(test_set), colnames(numericVariables))]
continousVariablesname <- getContinousset(dir)
print("Loaded Dataset")
##Missing Value Handling
source(paste0(dir,"/Code/missingValueHandler.R"))
#test_set <- getImputedData(test_set)
#numericVariables = getNumericVariables(test_set)
#categoricVariables <- test_set[setdiff(colnames(test_set), colnames(test_set))]
#write.csv(test_set, paste0(dir, "/Data/ImputedData_testSet.csv"), sep = ",")
test_set <- loadImputedTestSet(paste0(dir, "/Data/ImputedData_testSet.csv"))
#numericVariables = getNumericVariables(test_set)
#categoricVariables <- test_set[setdiff(colnames(test_set), colnames(numericVariables))]
print("Finished Missing Value Handling")
test_set <- test_set[sample(1:50000,5000, replace = FALSE),]
#Outlier Handling
source(paste0(dir, "/Code/Outliers.R"))
#z-score one-dimentional outlier handling
test_set_withoutOutlier<- handle.Outliers.for.Matrix(test_set)
print("Finished Outlier Handling")
#Data scaling with z-score
source(paste0(dir, "/Code/scaling.R"))
test_set <- z.scale.data(m=test_set,continous.var=continousVariablesname)
test_set_withoutOutlier<- z.scale.data(m=test_set_withoutOutlier,continous.var=continousVariablesname)
print("Finished Scaling")
source(paste0(dir, "/Code/ModelTrainer.R"))
selectedFeatures <- getSelectedFeatureSet(dir)
selectedFeatures <- c(as.vector(selectedFeatures[,1]))
test_set <- test_set[,selectedFeatures]
source(paste0(dir, "/Code/PCA.R"))
test_set<-rebuild_components_for_test_set(test_set)
print("Data is ready")
setwd("~/Documents/HU Berlin/WI 1516/refugeestest/IS refugees")
setwd("~/Documents/HU_Berlin/WI_1516/refugeestest/IS refugees")
source('~/Documents/HU_Berlin/WI_1516/refugeestest/IS refugees/pos_neg_anaysis.R')
library(ggmap)
map <- get_map(location = 'Europe', zoom = 4)
require(ggmap)
library(ggmap)
map <- get_map(location = 'Europe', zoom = 4)
setwd("~/Documents/HU_Berlin/WI_1516/refugeestest/IS refugees")
library(ggmap)
library(ggplot2)
map <- get_map(location = 'Europe', zoom = 4)
mapPoints <- ggmap(map) + geom_point(aes(x = longitude, y = latitude),data = negatives, alpha = .5, color = "red")
mapPoints
map <- get_map(location = "Europe", zoom = 4)
map <- get_map(location = "Europe", zoom = 4)
install.packages("ggmap")
require(ggmap)
require(ggmap)
